# About Project KinTrans

linedanceAI is leveraging its machine-learning platform to the deploy the first, 3D database of American Sign Language (ASL) body movements. The 3D format allows ASL, a movement-based language (sign movement happens in 3 spatial planes in relation to the body), to be analyzed in various domains as linguistics, software engineering and development, and neuroscience.  

Sign language is not only body movement, but also hand movement and facial movements communicating emotion, and meaning. This 3D body movement dataset of sign movements is complementary to these other technology stacks.

We seek the collaboration of research and engineering teams interested in advancing sign-technology for the NEW era of accessibility that is fast approaching. The dataset is available to view, search and analyze through an End User Licensing Agreement (EULA). Connect directly to learn more in advance info@linedanceAI.com. 

# About the ASL Dataset 

The Project KinTrans dataset contains 2820 unique sign movements, each sign movement with approximately 190 samples. In total, ~ 600,000 data samples were collected. The samples have been sourced from exclusively native ASL signers in Washington DC, Colorado, California and Texas and represent a wide variety of ‘style’ or ‘dialect. 

The complete release of the dataset in July 2021 will include feature data of all signs with skeletal viewer; a query feature by location, context, English gloss, and lexical class, side by side to analysis features and learning models.

# Dedicated USA Partners

## Washington DC
### ![The ASL APP](https://github.com/linedanceAI/Project-KinTrans/blob/master/Partners-Logos/TheASLApp.png?raw=true)
We are an app publishing and creative productions company that specializes in developing community and educational resources related to American Sign Language and Deaf Culture. Matt Malzkuhn, Co-Founder Ink & Salt LLC, [contact us here](mailto:matt@theaslapp.com). [Visit The ASL App](http://www.theaslapp.com/)

## Colorado
### ![Ktquiet LLC](https://github.com/linedanceAI/Project-KinTrans/blob/master/Partners-Logos/KtquietLLC.png?raw=true)
Ktquiet LLC is a Deaf-owned boutique consulting firm specializing in tailoring solutions to strengthen and grow organizations. [Contact us Here](mailto:ktquiet@gmail.com)

## California
### ![DCS](https://github.com/linedanceAI/Project-KinTrans/blob/master/Partners-Logos/DCS.png?raw=true)
DCS is an “…of, by, and for Deaf and Hard-of-Hearing” agency. DCS’ mission centers on meeting the social, economic, educational, and behavioral health needs of the Deaf and Hard of Hearing, DeafBlind and Late Deafened Community. [Visit us here](https://deafcommunityservices.org/)

## Texas
### ![ChileMarketing](https://github.com/linedanceAI/Project-KinTrans/blob/master/Partners-Logos/ChileMarketing.png?raw=true)
Deaf-owned marketing and web development agency. [Visit us here](https://chilmarketing.com/)

# Demographic representation: 28 Participants reporting
## Location and Partcipants
location | amount
-------- | -------
Washington DC | 14
Colorado | 4
California | 4
Texas | 6
## Race
race | amount
---- | ------
African American | 1
Mestizo | 5
South Asian | 1
White | 20
Race Not List | 1
## Educational Level
education | amount
--------- | ------
High School/GED | 3
2 Year College | 3
4 Year University | 10
Masters | 9
Ph.D. | 3
## Age
age range | amount
--------- | ------
18-25 | 10
26-30 | 2
31-35 | 6
36-40 | 6
41-45 | 2
51+ | 2
## Gender
gender | amount
------ | ------
Female | 13
Male | 15
## Hand Dominance
dominance | amount
--------- | ------
Right | 26
Left | 2
## Employment Status
status | amount
------ | ------
Student | 4
Employed | 17
self-Employed | 4
Not Employed, looking | 2
Not Employed, not looking | 1

# Data Collection Methodology
* The project team was responsible for locating potential Deaf partners from around the USA, securing contracts, managing partner and participant engagement, technical training/onboarding, video documentation, and project closure activities. Final partners were selected from Washington DC, Colorado, California and Texas.
* The data recording project originally began before COVID-19 and was designed to take place in groups. As COVID-19 evolved, participants received individual hardware systems (GPU-enabled laptop and Microsoft Azure Kinect DK) to use at their homes.
* Participants also contributed feedback for an updated movement recording software since they were working remote and often by themselves. The recorder needed a more touch-less experience for efficiency and ease of use. You can see the final recorder version in the [Movement Recorder Demo](https://youtu.be/q2mFrdUyJYc) video.

# Dedicated Project Management Team
* _Smitha Hanumantha_, Project Management Lead, Dallas: [LinkedIn Profile](https://www.linkedin.com/in/smithahanumantha/)
* _Trent Mora_, Project and Technical Support, Austin: [LinkedIn Profile](https://www.linkedin.com/in/trent-mora/)
* _Ryan Hutchison_, Strategic Community Consultant, Austin: [LinkedIn Profile](https://www.linkedin.com/in/ryandhutchison/)

# Video Documentation
* [Project Introduction](https://youtu.be/tIbBfb8B1lM)
* [Movement Recorder Demo](https://youtu.be/q2mFrdUyJYc)
* [ASL only project summary](https://youtu.be/mknaU4TyWlU) for Deaf partners and participants
* [Participant Experience](https://youtu.be/y0Pg9sJI3X4)

# Special Thanks 
* ADLINK Technology Inc is a special hardware partner to Project KinTrans. They have provided low footprint, rugged industrial CPUs embedded with powerful industrial GPU from NVDIA for data capture and rapid testing. The DLAP 3200 is a real AI workhorse. [ADLINK Website](https://www.adlinktech.com/en/index) 


# Hardware Requirements for Recording
## Machine
* Windows 10 April 2018 release (x64) or later
* Seventh Gen Intel® CoreTM i5 Processor (Quad Core 2.4 GHz or faster)
* 4 GB Memory
* NVIDIA GEFORCE GTX 1070 + or industrial grade equivalent found in ADLINK DLAP 3200.
* Dedicated USB3 port
## Camera
**Microsoft Azure Kinect DK** (depth sensor / color camera) was utilized for collection of the movement data. [Github documentation](https://github.com/microsoft/Azure-Kinect-Sensor-SDK)

# About linedanceAI
linedanceAI’s patented deep-learning technology generates insights from movements of human body joints. The technology performs mili-second segmentation analysis, analyzes similarities, and provides comparison analysis over any human movement data. Platform access provides enterprise users human movement feature data, manage custom data and analyze data to generate new feature sets in security, sports applications or accessibility domains.
The linedanceAI team is based in Dallas, Texas. info@linedanceAI.com

# Citations
Lexical content was curated from internal ASL linguist along with support from online resources.

ASL SignBank Julie A. Hochgesang, Onno Crasborn, and Diane Lillo-Martin. (2017-2020) ASL Signbank. New Haven, CT: Haskins Lab, Yale University. https://aslsignbank.haskins.yale.edu/

